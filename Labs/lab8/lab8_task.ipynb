{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **COMP 2211 Exploring Artificial Intelligence** #\n",
    "## Lab 8 Convolutional Neural Network (CNN) ##\n",
    "![cnn_cifar10.png](https://www.researchgate.net/publication/332284670/figure/fig1/AS:745591005007874@1554774156651/Example-of-a-CNN-for-image-classification_W640.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please run the following cells and do not modify anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def let_me_see(history):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"models\", exist_ok=True) # create a new folder \"models\" to save your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Pre-process the Cifar10 Dataset\n",
    "The CIFAR-10 dataset (Canadian Institute for Advanced Research, 10 classes) is a subset of the Tiny Images dataset and consists of 60000 32x32 color images. The images are labelled with one of 10 mutually exclusive classes: airplane, automobile (but not truck or pickup truck), bird, cat, deer, dog, frog, horse, ship, and truck (but not pickup truck). There are 6000 images per class with 5000 training and 1000 testing images per class.\n",
    "\n",
    "Some convention of notation:\n",
    "\n",
    "N: number of samples\n",
    "\n",
    "h: height of image\n",
    "\n",
    "w: width of image\n",
    "\n",
    "c: number of channels of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load the MNIST dataset and split it into training and testing sets\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # Perform data normalization\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "\n",
    "    # Convert the labels to one-hot encoded vectors\n",
    "    y_train = keras.utils.to_categorical(y_train)\n",
    "    y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "    # x_train: (N, h, w, c) = (50000, 32, 32, 3)\n",
    "    # y_train: (N, 10) = (50000, 10)\n",
    "    # x_test: (N, h, w, c) = (10000, 32, 32, 3)\n",
    "    # y_test: (N, 10) = (10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # There are 10 classes in CIFAR10 dataset\n",
    "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # visualize the picture in x_train\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(x_train[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"class{np.argwhere(y_train[i] == 1)[0][0]}: {classes[np.argwhere(y_train[i] == 1)[0][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 Data Augmentation\n",
    "\n",
    "After loading and preprocessing the data, we will now augment the data. Data augmentation is a technique to artificially increase the size of the training set by applying transformations to the images. This helps to reduce overfitting and improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1.1\n",
    "\n",
    "Build your data augmentation model.\n",
    "\n",
    "By default, the data augmentation model does not contain any data augmentation layers, but still runnable (you may try the default generator first to see how it performs).\n",
    "\n",
    "**Remember to add \"input_shape=img_shape\" to the first layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_augmentation(img_shape):\n",
    "    # Create a sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO 1.1\n",
    "    # Build your own model with model.add() and following layers\n",
    "    # Hint: you may consider using\n",
    "        # RandomFlip(mode): https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_flip/\n",
    "        # RandomRotation(factor): https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_rotation/\n",
    "        # RandomZoom(factor): https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom/\n",
    "    model.add()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward image through data augmentation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = Data_augmentation(img_shape=(32, 32, 3))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # visualize the augmented images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(data_aug(x_train[i: i+1])[0])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"class{np.argwhere(y_train[i] == 1)[0][0]}: {classes[np.argwhere(y_train[i] == 1)[0][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 CNN Model\n",
    "\n",
    "After preparing the data, we need to build a model to fit it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2.1\n",
    "Build your own CNN model\n",
    "\n",
    "**Remember to add \"input_shape=img_shape\" to the first layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myModel(img_shape, data_aug):\n",
    "    # Create a sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the data augmentation layer\n",
    "    model.add(data_aug)\n",
    "\n",
    "    # TODO 2.1\n",
    "    # Build your own model with model.add() and following layers\n",
    "    # Hint: you may consider using\n",
    "        # Conv2D(filters, kernel_size, activation='relu'): https://keras.io/api/layers/convolution_layers/convolution2d/\n",
    "        # MaxPooling2D(pool_size): https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
    "        # Flatten(): https://keras.io/api/layers/reshaping_layers/flatten/\n",
    "        # Dense(units, activation='relu'): https://keras.io/api/layers/core_layers/dense/\n",
    "        # Dropout(rate): https://keras.io/api/layers/regularization_layers/dropout/\n",
    "        # BatchNormalization(): https://keras.io/api/layers/normalization_layers/batch_normalization/\n",
    "        # GlobalAveragePooling2D(): https://keras.io/api/layers/pooling_layers/global_average_pooling2d/\n",
    "    model.add()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your own model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create the model\n",
    "    model = myModel(img_shape=(32, 32, 3), data_aug=data_aug)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", \"weights.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(x_train, y_train, epochs=30, batch_size=64, validation_split=0.2, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # load the best model\n",
    "    model = keras.models.load_model(os.path.join('models', 'weights.hdf5'))\n",
    "    # Evaluate the model on the test data\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize your own model history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    let_me_see(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission and Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can complete this task with adding data augmentations, running different number of epochs. \n",
    "\n",
    "Please make the final submission file size smaller than 200 MB (the zip which containing your lab8_tasks.ipynb and weights.hdf5) to make the ZINC submission smooth.\n",
    "\n",
    "As long as you can get the test accuracy above 75%, you will get full credit for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
