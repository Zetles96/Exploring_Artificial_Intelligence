{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqH5jRbX2YwZ"
      },
      "source": [
        "# COMP2211 PA1: K-nearest Neighbors Classifier for Wine Quality Prediction\n",
        "### Introduction\n",
        "The wine industry is highly competitive, and winemakers rely on chemical attributes like acidity, pH levels, residual sugar, and alcohol content to assess and predict wine quality. Accurate prediction is crucial for making informed production decisions and maintaining a good reputation.\n",
        "\n",
        "### Task Overview\n",
        "In this assignment, we will implement a K-Nearest Neighbors (KNN) classifier from scratch with Numpy to predict wine quality based on these attributes. Through this assignment, we will gain hands-on experience in data preprocessing, KNN model building, and model evaluation. Good luck and enjoy the journey!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT-kxulI837Y"
      },
      "source": [
        "## Data Description\n",
        "Our source dataset is winequality-white.csv, one of the [Wine Quality datasets](http://archive.ics.uci.edu/dataset/186/wine+quality) from UCI Machine Learning Repository (Note: you can download the dataset in the PA1 web page). It is related to white Vinho Verde wine samples from northern Portugal, containing 4,898 instances with 12 attributes. The input variables are based on physicochemical tests and include the following attributes: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, and alcohol. The output variable is the wine quality, represented by a score ranging from 0 to 10.\n",
        "\n",
        "Below is the list of column names, their roles and data type:\n",
        "<center>\n",
        "\n",
        "Column Name                            | Role | Type\n",
        "---------------------------------------|---------------|--------\n",
        "fixed_acidity                          | Feature       | Continuous\n",
        "volatile_acidit                        | Feature       | Continuous\n",
        "citric_acid                            | Feature       | Continuous\n",
        "residual_sugar                         | Feature       | Continuous\n",
        "chlorides                              | Feature       | Continuous\n",
        "free_sulfur_dioxide                    | Feature       | Continuous\n",
        "total_sulfur_dioxide                   | Feature       | Continuous\n",
        "density                                | Feature       | Continuous\n",
        "pH                                     | Feature       | Continuous\n",
        "sulphates                              | Feature       | Continuous\n",
        "alcohol                                | Feature       | Continuous\n",
        "quality                                | Target        | Integer\n",
        "\n",
        "</center>\n",
        "\n",
        "\n",
        "But don't be scared by the data! To finish the assignment, you don't really need to understand these chemical attributes. Having a rough idea of the data structure is enough.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIT2xENBySkK"
      },
      "source": [
        "## Task 0: Set-up\n",
        "Let's do all the basic set-up first!  \n",
        "\n",
        "Remarks: This part will not be graded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FerN9OW4NRE"
      },
      "source": [
        "### Task 0.1: Import libraries\n",
        "It's a good habit to import all libraries at the beginning of the code and it helps in the following aspects:\n",
        "*   Readability and clarity\n",
        "*   Avoiding namespace clashes\n",
        "*   Dependency management\n",
        "*   Consistency and convention\n",
        "\n",
        "Todo:  \n",
        "Please import your libraries in the following cell.  \n",
        "\n",
        "Remarks:\n",
        "1. We use [Numpy](https://numpy.org/) and [Pandas](https://pandas.pydata.org/) in this PA. You may also import other modules as long as they are part of the [Python Standard Library](https://docs.python.org/3/library/).  \n",
        "2. You are NOT allowed to use any other external libraries/functions\n",
        " (especially any machine learning library, e.g., sklearn) in todo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DWIyyARehnr"
      },
      "outputs": [],
      "source": [
        "# task 0.1: import libraries\n",
        "# todo start #\n",
        "\n",
        "\n",
        "# todo end #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXPkptPR5on3"
      },
      "source": [
        "### Task 0.2: Read Dataset\n",
        "Now you have the needed libraries in hand. Next, let's read the dataset from the source file to the project.  \n",
        "\n",
        "We assume you are working in Google Colab. One way to read a dataset in Google Colab:\n",
        "1. Download the source file and put it on your Google Drive\n",
        "2. Import the `drive` module from `google.colab` package\n",
        "3. Run `drive.mount` to mount your Google Drive to the Colab notebook\n",
        "4. Use `pandas.read_csv` to read the data from Google Drive and store the data in pandas DataFrame\n",
        "\n",
        "Todo:\n",
        "Modify `YourFilePath` depending on the actual directory to read the data to this notebook.\n",
        "\n",
        "Remarks:  \n",
        "You can check whether your data reading is successful by running the next cell. The shape should be (4892, 12). You can also see the first 5 rows of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVXEVtX_0278",
        "outputId": "9008ebe3-7ffa-4d2f-c7e1-2b684925462b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Task 0.2: read dataset\n",
        "if __name__ == '__main__':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "# todo start #\n",
        "# please modify YourFilePath\n",
        "    data = pd.read_csv('/content/drive/MyDrive/YourFilePath', delimiter=';')\n",
        "# todo end #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "14vb_9tLy9d-",
        "outputId": "eac5c5f7-8c3a-4569-fbaa-7c6befacf925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data shape: (4898, 12)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8efbfead-823d-4ed2-af1a-1ef1218c3abe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.0010</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.9951</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8efbfead-823d-4ed2-af1a-1ef1218c3abe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8efbfead-823d-4ed2-af1a-1ef1218c3abe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8efbfead-823d-4ed2-af1a-1ef1218c3abe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5a01ee38-bca1-455b-9d29-883eb47e9ff6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a01ee38-bca1-455b-9d29-883eb47e9ff6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5a01ee38-bca1-455b-9d29-883eb47e9ff6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.0              0.27         0.36            20.7      0.045   \n",
              "1            6.3              0.30         0.34             1.6      0.049   \n",
              "2            8.1              0.28         0.40             6.9      0.050   \n",
              "3            7.2              0.23         0.32             8.5      0.058   \n",
              "4            7.2              0.23         0.32             8.5      0.058   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
              "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
              "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
              "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
              "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      8.8        6  \n",
              "1      9.5        6  \n",
              "2     10.1        6  \n",
              "3      9.9        6  \n",
              "4      9.9        6  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    [numRow, numCol] = data.shape\n",
        "    print(\"data shape:\", data.shape)\n",
        "    data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMYW38ML0BTC"
      },
      "source": [
        "## Task 1: Data Preprocessing\n",
        "Before building our KNN model, let's get all the needed data. The raw data is usually not enough but needs to be preprocessed. There are many methods in the concept of data preprocessing.  \n",
        "\n",
        "In this section, we will explore two basic methods: [Data Splitting](https://www.geeksforgeeks.org/splitting-data-for-machine-learning-models/) and [Data Normalization](https://www.geeksforgeeks.org/what-is-data-normalization/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA-BB9rp1EZg"
      },
      "source": [
        "### Task 1.1: Data Splitting\n",
        "Now `data` is our dataset with shape (4898, 12). We need to split the data for training and testing purposes. In this project, we let the training data contain the first 4000 rows and the testing data contain the remaining 898 rows. Also, we need to split the data into features and label (commonly called X and y in machine learning) arrays.\n",
        "\n",
        "Todo:  \n",
        "Split the Pandas dataframe `data` and store in Numpy arrays `X_train`, `y_train`, `X_test`, `y_test`.  \n",
        "\n",
        "Remarks:  \n",
        "1. This task would not be graded.\n",
        "2. As we use many numpy functions later on, the output should be numpy arrays.\n",
        "\n",
        "Pandas functions you may use:  \n",
        "`pandas.DataFrame.drop`, `pandas.DataFrame.iloc`, `pandas.DataFrame.to_numpy`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoS_jrDJzD1f",
        "outputId": "a6394c13-97d3-4fb2-c91e-629d0fdd83f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (4000, 11) and y_train shape: (4000,)\n",
            "X_test shape: (898, 11) and y_test shape: (898,)\n"
          ]
        }
      ],
      "source": [
        "# Task 1.1\n",
        "if __name__ == '__main__':\n",
        "    # todo start #\n",
        "\n",
        "\n",
        "\n",
        "    # todo end #\n",
        "    print(\"X_train shape: {} and y_train shape: {}\".format(X_train.shape, y_train.shape))\n",
        "    print(\"X_test shape: {} and y_test shape: {}\".format(X_test.shape, y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjLNkLMj2t0n"
      },
      "source": [
        "### Task 1.2: Data Normalization\n",
        "\n",
        "Normalization is a fundamental preprocessing step in machine learning. It helps to ensure fair treatment of features, facilitate efficient optimization, enhance interpretability, handle different measurement units, and mitigate the impact of outliers. By normalizing the data, we can improve the accuracy and reliability of machine learning models.  \n",
        "\n",
        "Let's introduce 2 common normalization methods: [**Min-Max Normalization** ](https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)) and [ **Z-score Normalization**](https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)). Suppose $X:(x_1, x_2, ..., x_n)$ is a column (corresponding to a feature), then\n",
        "1. min-max normalization:  \n",
        "### $X_{min-max-normalized} = \\frac{X-X_{min}}{X_{max} - X_{min}}$\n",
        "2. z-score normalization:  \n",
        "### $X_{Z-score-normalized} = \\frac{X-\\mu_X}{\\sigma_X}$\n",
        "\n",
        "Todo:  \n",
        "Please implement `min_max_normalization(input_array)` and `z_score_normalization(input_array)`.  \n",
        "\n",
        "Numpy functions you may use:  \n",
        "`numpy.mean`, `numpy.min`, `numpy.max`, `numpy.std` ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGycdo2c3nBs"
      },
      "outputs": [],
      "source": [
        "# Task 1.2.1\n",
        "def min_max_normalization(input_array):\n",
        "  # input_array: numpy array of shape (num_rows, num_features)\n",
        "  # todo start #\n",
        "\n",
        "\n",
        "\n",
        "  # todo end #\n",
        "  return normalized_array\n",
        "  # normalized_array: numpy array of shape (num_rows, num_features)\n",
        "\n",
        "# Task 1.2.2\n",
        "def z_score_normalization(input_array):\n",
        "  # input_array: numpy array of shape (num_rows, num_features)\n",
        "  # todo start #\n",
        "\n",
        "\n",
        "\n",
        "  # todo end #\n",
        "  return normalized_array\n",
        "  # normalized_array: numpy array of shape (num_rows, num_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OyMc47l8GDr"
      },
      "source": [
        "## Task 2: KNN Model\n",
        "Now, the training data and testing data are ready. Let's build the KNN model!  \n",
        "\n",
        "In this session, we break down the KNN model into the following functional parts:\n",
        "1. Distance Calculation\n",
        "2. K Nearest Neighbors Finding\n",
        "3. Prediction Generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C0EGRys8Jz4"
      },
      "source": [
        "### Task 2.1: Distance Calculation\n",
        "\n",
        "In KNN, distance calculation plays an important role as we need to find the k nearest neighbors to make the prediction. Here, we introduce 2 common distance calculation methods: [**Euclidean Distance**](https://en.wikipedia.org/wiki/Euclidean_distance) and [**Manhattan Distance**](https://en.wikipedia.org/wiki/Taxicab_geometry). Suppose we are calculating the distance between $X:(x_1, x_2, ... ,x_n)$ and $Y:(y_1, y_2, ... y_n)$ in n-dimensional space.\n",
        "\n",
        "1. Euclidean Distance:  \n",
        "### $d(X, Y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$\n",
        "2. Manhattan Distance:  \n",
        "### $d(X, Y) = \\sum_{i=1}^{n} \\lvert (x_i - y_i) \\rvert $\n",
        "\n",
        "Todo:  \n",
        "Please implement `euclidean_distance(X_train, X_test)` and `manhattan_distance(X_train, X_test)`.  \n",
        "\n",
        "Numpy functions you may use:  \n",
        "`numpy.expand_dims`, `numpy.sqrt`, `numpy.sum` ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "874Wvw6V7LP2"
      },
      "outputs": [],
      "source": [
        "# Task 2.1.1\n",
        "def euclidean_distance(X_train, X_test):\n",
        "  # X_train: numpy array of shape (num_rows_train, num_features)\n",
        "  # X_test: numpy array of shape (num_rows_test, num_features)\n",
        "  # todo start #\n",
        "\n",
        "\n",
        "\n",
        "  # todo end #\n",
        "  return distance\n",
        "  # distance: numpy array of shape (num_rows_test, num_rows_train)\n",
        "\n",
        "# Task 2.1.2\n",
        "def manhattan_distance(X_train, X_test):\n",
        "  # X_train: numpy array of shape (num_rows_train, num_features)\n",
        "  # X_test: numpy array of shape (num_rows_test, num_features)\n",
        "  # todo start #\n",
        "\n",
        "\n",
        "\n",
        "  # todo end #\n",
        "  return distance\n",
        "  # distance: numpy array of shape (num_rows_test, num_rows_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqB3RORp9tmy"
      },
      "source": [
        "### Task 2.2: Find K Nearest Neighbors\n",
        "\n",
        "Now we have the distance calculation functions; the next step is to find the k nearest neighbors for each test point.  \n",
        "\n",
        "Todo:  \n",
        "Please implement `find_k_nearest_neighbor(distance, y_train, k)`  \n",
        "\n",
        "Remarks:\n",
        "1. In case there is a tie, which means more than 1 training points share the same distance between a testing point, we consider the training point with smaller index as smaller (Can search the concept of stable sort).\n",
        "\n",
        "\n",
        "Numpy functions you may use:  \n",
        "`numpy.argsort`, `numpy.take`, `numpy.take_along_axis` ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBNCINxrx7lM"
      },
      "outputs": [],
      "source": [
        "def find_k_nearest_neighbor(distance, y_train, k):\n",
        "  # distance: numpy array of shape (num_rows_test, num_rows_train), return value from previous distance functions\n",
        "  # y_train: numpy array of shape (num_rows_train, ),  the labels of training data\n",
        "  # k: integer, k in \"K-nearest neighbors\"\n",
        "  # todo start #\n",
        "\n",
        "\n",
        "\n",
        "  # todo end #\n",
        "  return y_neighbor, distance_neighbor\n",
        "  # y_neighbor: numpy array of shape (num_rows_test, k), the labels of the k nearest neighbors of each test point\n",
        "  # distance_neighbor: numpy array of shape (num_rows_test, k),  the distance between each test point and its k nearest neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Neeuk6gjA_xs"
      },
      "source": [
        "### Task 2.3: Weighted Average Prediction\n",
        "\n",
        "In weighted average prediction, each data point's contribution to the final prediction is weighted based on its importance or relevance. The weights can be assigned manually or determined through a learning algorithm. Higher weights indicate higher importance (we set the weights manually here). The final prediction is obtained by taking the weighted average of the predictions made on each data point.\n",
        "\n",
        "Target:\n",
        "Suppose the labels of k nearest neighbors of a test point are $Y:(y_1, y_2, ..., y_k)$, and the manually assigned weights are $W:(w_1, w_2, ..., w_k)$. Then the prediction value of this point should be\n",
        "\n",
        "$$\n",
        "  y_{\\text{pred}} = \\frac{y_1 w_1 + \\cdots + y_k w_k}{w_1 + \\cdots + w_k}\n",
        " = \\frac{\\displaystyle \\sum_{i=1}^{k} y_i w_i}{\\displaystyle \\sum_{i=1}^{k} w_i}\n",
        "$$\n",
        "Todo:\n",
        "Please implement `weighted_average_predict(y_neighbor, weights=None)`\n",
        "\n",
        "Remarks:\n",
        "1. the parameter `weights` here is optional. If no `weights` array is passed into the function, then we should treat each of k nearest neighbors equally.  \n",
        "\n",
        "Numpy functions you may use:  \n",
        "`numpy.expand_dims`, `numpy.sum` ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du9q2c-9yM9K"
      },
      "outputs": [],
      "source": [
        "def weighted_average_predict(y_neighbor, weights=None):\n",
        "  # y_neighbor: numpy array of shape (num_rows_test, k), the labels of the k nearest neighbors of each test point\n",
        "  # weights: numpy array of shape (k, ), controls the contribution of each near enighbor\n",
        "  # todo start #\n",
        "\n",
        "\n",
        "\n",
        "  # todo end #\n",
        "  return prediction\n",
        "  # prediction: numpy array of shape (num_rows_test, ), the weighted average prediction for each test point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koWDA4QcB6sg"
      },
      "source": [
        "### Task 2.4: Distance-based Prediction\n",
        "\n",
        "Distance-based weighted prediction assigns weights to data points based on their proximity or similarity to the query point. The idea is that closer data points are more likely to influence the prediction more than those farther away. Here, we use a common method: let the weights are inversely proportional to the distance from the query point.\n",
        "\n",
        "Target:\n",
        "Suppose the labels of k nearest neighbors of a test point are $Y:(y_1, y_2, ..., y_k)$, and the distances between each neighbor and the test point are $D:(d_1, d_2, ..., d_k)$. Then\n",
        "$\\displaystyle y_{\\text{pred}} = \\frac{\\sum_{i=1}^{k} y_iw_i}{\\sum_{i=1}^{k} w_i} $ where $\\displaystyle w_i = \\frac{1}{d_i + \\varepsilon}$.  \n",
        "Notice we use $\\varepsilon$ here to avoid division by zero problem.\n",
        "\n",
        "Todo:\n",
        "Please implement `distance_based_predict(y_neighbor, distance_neighbor, epsilon=1)`\n",
        "\n",
        "Numpy functions you may use:  \n",
        "`numpy.sum` ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSNM8BHKyQxL"
      },
      "outputs": [],
      "source": [
        "def distance_based_predict(y_neighbor, distance_neighbor, epsilon):\n",
        "  # y_neighbor: numpy array of shape (num_rows_test, k), the labels of the k nearest neighbors of each test point\n",
        "  # distance_neighbor, numpy array of shape (num_rows_test, k), the distance between the each k nearest neighbor and test point\n",
        "  # epsilon: positive number, to avoid dividing by zero problem\n",
        "  # todo start #\n",
        "\n",
        "\n",
        "\n",
        "  # todo end #\n",
        "  return prediction\n",
        "  # prediction: numpyt array of shape (num_rows_test, ), the distance-based prediction for each test point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07QwcMhf9xQ1"
      },
      "source": [
        "## Task 3: Metric Analyzer\n",
        "\n",
        "Using appropriate metrics to analyze machine learning models is of utmost importance as it enables quantitative performance assessment, facilitates model comparison and provides valuable insights into the model's effectiveness, aiding in informed decision-making and continuous improvement of the learning algorithms. In this task, we introduce 3 metrics.  \n",
        "\n",
        "Suppose $A:(a_1, a_2, ..., a_n)$ is actual labels and $P:(p_1, p_2, ... , p_n)$ is predicted labels.\n",
        "The 3 metrics here to analyze the prediction quality are:\n",
        "1.   [Mean Absolute Error](https://en.wikipedia.org/wiki/Mean_absolute_error): $MAE = \\frac{\\sum_{i=1}^{n}{\\lvert a_i - p_i \\rvert}}{n}$\n",
        "\n",
        "2.   [Mean Square Error](https://en.wikipedia.org/wiki/Mean_squared_error): $MSE = \\frac{\\sum_{i=1}^n {(a_i - p_i)^2}}{n}$\n",
        "\n",
        "3.   [Mean Absolute Percentage Error](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error): $MAPE = \\frac{\\sum_{i=1}^{n}{\\lvert \\frac{a_i - p_i}{a_i} \\rvert}}{n}$\n",
        "\n",
        "Todo:  \n",
        "Please implement `metric_analyze(y_true, y_pred)`\n",
        "\n",
        "Numpy functions you may use:  \n",
        "`numpy.mean`, `numpy.min`, `numpy.absolute`...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFkov6GgZvrd"
      },
      "outputs": [],
      "source": [
        "def metric_analyze(y_true, y_pred):\n",
        "  # y_true: numpy array of shape (num_rows_test, )\n",
        "  # y_pred: numpy array of shape (num_rows_test, )\n",
        "  # Task 3: metric calculation\n",
        "  # todo start #\n",
        "\n",
        "\n",
        "\n",
        "  # todo end #\n",
        "  return mae, mse, mape\n",
        "  # mae, mse, mape: number, the metric value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJkbP0S-AICP"
      },
      "source": [
        "## Task 4: D-Fold Cross-validation\n",
        "\n",
        "[D-fold cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation) is a widely used technique in machine learning for evaluating model performance. It involves dividing the dataset into k subsets or folds, training the model D times using different folds as the validation set, and the rest as the training set. By rotating the folds as the validation set, D-fold cross-validation provides a more reliable estimate of the model's generalization ability. The performance metrics from each iteration are then averaged to assess the model's effectiveness. This approach is valuable for model evaluation, hyperparameter tuning, and comparing different algorithms.  \n",
        "\n",
        "[Good explanation](https://scikit-learn.org/stable/modules/cross_validation.html)  \n",
        "[Video introduction](https://www.youtube.com/watch?v=TIgfjmp-4BA&ab_channel=Udacity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ig0ksdrFEGJ"
      },
      "source": [
        "### Task 4.1: Split D Folds\n",
        "To do D-fold cross-validation, we need the D folds of training and testing data. We can first divide the original dataset into k equal-sized parts. Each part represents a distinct subset of the data and is used as training and testing data during cross-validation. Specifically, each fold serves as the test set once while the remaining D-1 folds are used for training.\n",
        "\n",
        "Todo:  \n",
        "Please implement `split_d_fold(X, y, d)`\n",
        "\n",
        "Remarks:\n",
        "1. D-fold cross validation is actually better known as K-fold cross validation, but we wanted to distinguish the \"k\" in \"K Nearest Neighbors\".\n",
        "2. In theory, it's better to shuffle the dataset before splitting. We don't need to do it here.\n",
        "3. The order of the train and test fold matters and should correspond. This simply means the i-th train fold and the i-th test fold should be able to be combined into one original data set.\n",
        "4. Because number of records in original data is not necessarily divisible by d, the size of each training fold may vary, but will only differ by at most 1 (same for test fold)\n",
        "\n",
        "Numpy functions you may use:  \n",
        "`numpy.array_split`, `numpy.concatenate`, `numpy.absolute` ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi0nnGelywAG"
      },
      "outputs": [],
      "source": [
        "def split_d_fold(X, y, d):\n",
        "  # X: numpy array of shape (num_rows, num_features), the feature data\n",
        "  # y: numpy array of shape (num_rows, ), the label data\n",
        "  # d: integer, number of folds\n",
        "  data = np.concatenate((X, y[:, np.newaxis]), axis=1) # for better data structure\n",
        "  # todo start #\n",
        "\n",
        "\n",
        "\n",
        "  # todo end #\n",
        "  return train_d_folds, test_d_folds\n",
        "  # train_d_folds: a pyhon list of length d, each entry is a training fold, each fold contains both features and labels\n",
        "  # test_d_folds: a python list of length d, each entry is a testing fold, each fold contains both features and labels\n",
        "  # the the i-th entry of train_d_folds and test_d_folds are corresponding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BHKs7Fp_N44"
      },
      "source": [
        "### Task 4.2: Cross-Validation\n",
        "Now, we have the training and testing folds in hand. We use these D folds to validate the performance of KNN models with different functional parts settings. The point here is doing cross-validation regardless of the detailed model to be validated. The skeleton is provided to you.\n",
        "\n",
        "Todo:  \n",
        "1. Read and understand the provided code.\n",
        "2. Generate X_train, X_test, y_train, y_test for each round.\n",
        "3. Predict with the KNN model composed with previously implemented functional parts.\n",
        "4. Analyze the prediction with metric(s) and store the score in scores.\n",
        "\n",
        "For grading purposes, you are required to do the cross-validation for this scenario:\n",
        "1. The KNN model uses Euclidean distance and distance-based prediction\n",
        "2. Use MSE as a major metric\n",
        "\n",
        "Remarks:  \n",
        "Only `cross_validate_grading()` would be graded. Please ensure your code is designed for the above scenario. No score would be given whenever the result is wrong, even if your idea is totally correct.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmzl7i4Iy2Cs"
      },
      "outputs": [],
      "source": [
        "def cross_validate_sample(train_d_folds, test_d_folds, k_list):\n",
        "  # train_d_folds: a pyhon list of length d, each entry is a training fold\n",
        "  # test_d_folds: a python list of length d, each entry is a testing fold\n",
        "  # k_list: a python list, contains the k to be validated\n",
        "  # the the i-th entry of train_d_folds and test_d_folds are corresponding\n",
        "  scores = np.zeros((len(k_list), len(train_d_folds)))\n",
        "  # scores: a numpy array of shape (len(k_list), len(d_folds)), contains the metric for specific k and fold\n",
        "  for k_index, k in enumerate(k_list):\n",
        "    for fold in range(len(train_d_folds)):\n",
        "      # todo start #\n",
        "\n",
        "\n",
        "\n",
        "      # todo end #\n",
        "  mean_scores = np.mean(scores, axis=1, keepdims=False)\n",
        "  return mean_scores\n",
        "  # mean_scores: numpy array of shape(len(k_list), ), the mean score for each k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDER2cFEchBv"
      },
      "outputs": [],
      "source": [
        "def cross_validate_grading(train_d_folds, test_d_folds, k_list):\n",
        "  # train_d_folds: a pyhon list of length d, each entry is a training fold\n",
        "  # test_d_folds: a python list of length d, each entry is a testing fold\n",
        "  # k_list: a python list, contains the k to be validated\n",
        "  # the the i-th entry of train_d_folds and test_d_folds are corresponding\n",
        "  scores = np.zeros((len(k_list), len(train_d_folds)))\n",
        "  # scores: a numpy array of shape (len(k_list), len(d_folds)), contains the metric for specific k and fold\n",
        "  for k_index, k in enumerate(k_list):\n",
        "    for fold in range(len(train_d_folds)):\n",
        "      # todo start #\n",
        "\n",
        "\n",
        "\n",
        "      # todo end #\n",
        "  mean_scores = np.mean(scores, axis=1, keepdims=False)\n",
        "  return mean_scores\n",
        "  # mean_scores: numpy array of shape(len(k_list), ), the mean score for each k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOq1eNJg_OOK"
      },
      "source": [
        "### Task 4.3: First, the Best K\n",
        "Suppose we used `cross_validate` to get the mean score for each k in the k-list. Now it's time to decide which k is the best. Suppose we first care about the prediction quality (which means score, in our case, the lower score means better prediction). When the prediction qualities for 2 k are the same, we pick the smaller one to improve efficiency.\n",
        "\n",
        "Todo:  \n",
        "Please implement `find_best_k`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaHTRLSRy3wz"
      },
      "outputs": [],
      "source": [
        "def find_best_k(k_list, mean_scores):\n",
        "  # k_list: a python list, contains the k to be validated, order is not guaranteed\n",
        "  # mean_scores: a numpy array of shape (len(k_list), ), the mean score for each k\n",
        "  # todo start #\n",
        "\n",
        "\n",
        "\n",
        "  # todo end\n",
        "  return best_k\n",
        "  # best_k: number, value of the smallest k that obtain best mean score in the cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhSxXCzq5mYu"
      },
      "source": [
        "## Playground: Try out your model here\n",
        "We provide some code only for your self-testing purposes. After you finish all tasks, you can try to run the testing code. If an error occurs, please go back and check your code carefully.\n",
        "\n",
        "This part will not be graded.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn-9AY4K9KV3"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    normalized_X_train = min_max_normalization(X_train)\n",
        "    normalized_X_test = min_max_normalization(X_test)\n",
        "    distance = euclidean_distance(normalized_X_train, normalized_X_test)\n",
        "    y_neighbor, distance_neighbor = find_k_nearest_neighbor(distance, y_train, 7)\n",
        "    y_pred = distance_based_predict(y_neighbor, distance_neighbor, 1)\n",
        "    print(metric_analyze(y_pred, y_test))\n",
        "    train_d_folds, test_d_folds = split_d_fold(normalized_X_train, y_train, 5)\n",
        "    list_k = [11,13,15,17,19]\n",
        "    print(find_best_k(list_k, cross_validate_sample(train_d_folds, test_d_folds, list_k)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo9g81SdpxfW"
      },
      "source": [
        "### Optional Task:\n",
        "Compare your KNN model with the standard KNN model in scikit-learn. Which one is better in terms of accuracy? What about efficiency? Think about the outcomes and discuss your ideas with others!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FeNwe4Fpvsr",
        "outputId": "f3e61d50-11fb-4fdc-a40f-14a7f8e8dc63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "(0.6581291759465479, 0.920935412026726, 0.10962853961183584)\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    !pip install scikit-learn\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    knn = KNeighborsClassifier(n_neighbors = 11)\n",
        "    knn.fit(normalized_X_train, y_train)\n",
        "    y_pred = knn.predict(normalized_X_test)\n",
        "    print(metric_analyze(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
